{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b148516c-6132-491f-a071-570fbebb9a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import asyncio\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from redis import client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e9ea426-8bc0-468b-8e6a-04a9544c539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "DATA_LOCATION = \"/data\"\n",
    "REDIS_HOST=\"172.20.0.20\"\n",
    "REDIS_PORT=\"6379\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6f7920-5eeb-4018-99e8-e3dc4b974f16",
   "metadata": {},
   "source": [
    "## 1. Prepare Feature Store\n",
    "\n",
    "First, the features need to be loaded into redis so that our loan prediction model can retrieve them at inference time. To do this, we will load in our datasets with Pandas, and set all the rows of the `zipcode` and `credit` datasets as Redis hashes.\n",
    "\n",
    "In Redis, hashes are like Python dictionaries with keys and values. One key is used to reference the entire dictionary. For the zipcode dataset this will be the `zipcode` column and for the credit dataset this will be the `dob_ssn` column.\n",
    "\n",
    "The following functions will connect to Redis and store our feature data as described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13aad05d-9269-4f50-a64c-0954a9572020",
   "metadata": {},
   "outputs": [],
   "source": [
    "redis_client = client.Redis(host=REDIS_HOST, port=REDIS_PORT)\n",
    "\n",
    "def prepare_feature_store(data_path):\n",
    "    credit_dataset = pd.read_parquet(f\"{data_path}/credit_history.parquet\")\n",
    "    zipcode_dataset = pd.read_parquet(f\"{data_path}/zipcode_table.parquet\")\n",
    "\n",
    "    # Drop unused features\n",
    "    zipcode_dataset = zipcode_dataset.drop(columns=[\"city\",\n",
    "                                                    \"state\",\n",
    "                                                    \"location_type\",\n",
    "                                                    \"event_timestamp\",\n",
    "                                                    \"created_timestamp\"])\n",
    "    credit_dataset = credit_dataset.drop(columns=[\"event_timestamp\", \"created_timestamp\"])\n",
    "    load_dataframe(\"dob_ssn\", credit_dataset)\n",
    "    load_dataframe(\"zipcode\", zipcode_dataset)\n",
    "    \n",
    "def load_dataframe(key_name, df):\n",
    "    records = df.to_dict(orient=\"records\")\n",
    "    pipe = redis_client.pipeline()\n",
    "    for record in records:\n",
    "        key = record.pop(key_name)\n",
    "        pipe.hset(key, mapping=record)\n",
    "    pipe.execute()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b50884a9-84bf-4b76-bd43-4cb90f830520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 21s, sys: 1.8 s, total: 1min 23s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# this should take about 2 minutes\n",
    "prepare_feature_store(DATA_LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca1e16d-07ef-4f2b-910d-c40dae53830b",
   "metadata": {},
   "source": [
    "Now we can check to see the feature data loaded into Redis and what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc7cb8a3-c535-4901-a648-3d0d43aec608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Keyspace\n",
      "db0:keys=57477,expires=0,avg_ttl=0\n"
     ]
    }
   ],
   "source": [
    "!redis-cli -h $REDIS_HOST -p $REDIS_PORT info keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c89220e-4496-455a-be3d-c845db4fc651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) \"credit_card_due\"\n",
      " 2) \"3304\"\n",
      " 3) \"mortgage_due\"\n",
      " 4) \"958801\"\n",
      " 5) \"student_loan_due\"\n",
      " 6) \"45454\"\n",
      " 7) \"vehicle_loan_due\"\n",
      " 8) \"18259\"\n",
      " 9) \"hard_pulls\"\n",
      "10) \"0\"\n",
      "11) \"missed_payments_2y\"\n",
      "12) \"0\"\n",
      "13) \"missed_payments_1y\"\n",
      "14) \"0\"\n",
      "15) \"missed_payments_6m\"\n",
      "16) \"0\"\n",
      "17) \"bankruptcies\"\n",
      "18) \"0\"\n"
     ]
    }
   ],
   "source": [
    "# get a random entry from the credit features\n",
    "!redis-cli -h $REDIS_HOST -p $REDIS_PORT hgetall 19660915_3573"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca3abd18-8d52-4645-bc4f-7a2dcad1f5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) \"tax_returns_filed\"\n",
      "2) \"2956\"\n",
      "3) \"population\"\n",
      "4) \"5193\"\n",
      "5) \"total_wages\"\n",
      "6) \"140664086\"\n"
     ]
    }
   ],
   "source": [
    "# get a random entry from the zipcode features.\n",
    "!redis-cli -h $REDIS_HOST -p $REDIS_PORT hgetall 12542"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6732d7da-93e2-4715-bfe7-8f9003fcdb37",
   "metadata": {},
   "source": [
    "## 2. Prepare Inference Workflow\n",
    "\n",
    "The inference workflow will have 4 components to it that we will use the RedisAI Directed Acyclic Graph construct to string into a single call to Redis. \n",
    "<img src=\"../assets/workflow.png\" alt=\"drawing\" style=\"display:block;margin-left:auto;margin-right: auto;width: 30%;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bbabb8-f0c6-43cc-9472-53ea0fd61a24",
   "metadata": {},
   "source": [
    "The RedisAI scripting interface uses TorchScript, JIT-traced Python, to run pre/post processing scripts needed for infernce workflows. The entire TorchScript library, with all it's available functions, can be used without needing to worry about dependencies because it's all built in.\n",
    "\n",
    "Every script in RedisAI has `entry_points` which are functions that can be called within the script by name. All `entry_points` have the same function signature:\n",
    "```python\n",
    "def script(tensors: List[Tensor], keys: List[str], args: List[str]):\n",
    "```\n",
    "`Tensors` are the input tensors, stored in Redis, that are passed to this function directly.\n",
    "`Keys` are the Redis keys that will be accessed during the execution of this function.\n",
    "`args` are request time strings that can be additionally passed to a script from the client side.\n",
    "\n",
    "\n",
    "For this workflow, we will use the script interface to\n",
    "- Recieve the input request\n",
    "- Lookup credit and zipcode features stored in Redis\n",
    "- Take feature values from Redis hashes and convery to float values\n",
    "- Prepare an input torch.Tensor for our model\n",
    "\n",
    "In order to have RedisAI collect the needed features, we create a `enrich_features` script that takes in two components:\n",
    "1. `args`: Request time features (age, income, employment length, etc)\n",
    "2. `keys`: Lookup features (zipcode, dob_ssn)\n",
    "\n",
    "Since our feature data is not stored as tensors, no tensors will be passed to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d22279dd-ce42-4969-8277-48b2a92573e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script.py\n",
    "def enrich_features(tensors: List[Tensor], keys: List[str], args: List[str]):\n",
    "    features = args\n",
    "    credit_features = [str(x) for x in redis.asList(redis.execute(\"HVALS\", keys[0]))]\n",
    "    zipcode_features = [str(x) for x in redis.asList(redis.execute(\"HVALS\", keys[1]))]\n",
    "    features.extend(credit_features)\n",
    "    features.extend(zipcode_features)\n",
    "    input_tensor = torch.tensor([float(feature) for feature in features]).reshape(1,17)\n",
    "    return input_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7ccf21c-0111-4d25-8207-8b9fdf17d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can load the script into Redis and call it to test it.\n",
    "import redisai\n",
    "rai_client = redisai.Client(host=REDIS_HOST, port=REDIS_PORT)\n",
    "\n",
    "def load_script(script_path, rai_client):\n",
    "    with open(script_path, \"r\") as f:\n",
    "        script_bytes = f.read()\n",
    "\n",
    "    rai_client.scriptstore(\"get_loan_features\",\n",
    "                           device=\"CPU\",\n",
    "                           script=script_bytes,\n",
    "                           entry_points=[\"enrich_features\"],\n",
    "                           tag=\"v1\")\n",
    "load_script(\"./script.py\", rai_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fba3c04-9c55-48cf-ab9e-23bfecb8941d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) \"key\"\n",
      " 2) \"get_loan_features\"\n",
      " 3) \"type\"\n",
      " 4) \"SCRIPT\"\n",
      " 5) \"backend\"\n",
      " 6) \"TORCH\"\n",
      " 7) \"device\"\n",
      " 8) \"CPU\"\n",
      " 9) \"tag\"\n",
      "10) \"v1\"\n",
      "11) \"duration\"\n",
      "12) (integer) 0\n",
      "13) \"samples\"\n",
      "14) (integer) -1\n",
      "15) \"calls\"\n",
      "16) (integer) 0\n",
      "17) \"errors\"\n",
      "18) (integer) 0\n"
     ]
    }
   ],
   "source": [
    "# check to ensure the script was loaded correctly\n",
    "!redis-cli -h $REDIS_HOST -p $REDIS_PORT AI.INFO get_loan_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e33c2d5e-ff55-450a-a0e7-9c173a5b2354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipcode = \"12542\"\n",
    "dob_ssn = \"19510613_1349\"\n",
    "request_features = {\n",
    "    \"age\": \"29\",\n",
    "    \"income\": \"100000\",\n",
    "    \"yr_employment_length\": \"3\",\n",
    "    \"loan_amount\": \"10000000\",\n",
    "    \"loan_int_rate\": \"7.2\"\n",
    "}\n",
    "output_keyname = \"sample_script_out\"\n",
    "rai_client.scriptexecute(\"get_loan_features\",\n",
    "                         \"enrich_features\",\n",
    "                         keys=[zipcode, dob_ssn],\n",
    "                         args=list(request_features.values()),\n",
    "                         outputs=[output_keyname]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3600c37-5e32-488b-af70-99b9c9488f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.9000000e+01, 1.0000000e+05, 3.0000000e+00, 1.0000000e+07,\n",
       "        7.1999998e+00, 2.9560000e+03, 5.1930000e+03, 1.4066408e+08,\n",
       "        3.6850000e+03, 1.5685300e+05, 1.8900000e+04, 3.9410000e+03,\n",
       "        1.0000000e+00, 7.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "        2.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the result of the script execution which\n",
    "# is the collected list of features from our\n",
    "# two feature datasets (credit and zipcode)\n",
    "# stored in Redis\n",
    "rai_client.tensorget(output_keyname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0dcede-4c18-4e57-8110-33a61879455f",
   "metadata": {},
   "source": [
    "## 2.1 Load Model\n",
    "\n",
    "At this point you should have trained the model in the notebook located in this repo and saved it into the `DATA_LOCATION` directory listed above. For the XGBoost model, the RedisAI ONNX backend will be used. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "283fb31f-871d-42c8-872a-d4bb151801b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model(model_path, rai_client):\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model_bytes = f.read()\n",
    "\n",
    "    rai_client.modelstore(\"loan_model\",\n",
    "                          backend=\"ONNX\",\n",
    "                          device=\"CPU\",\n",
    "                          data=model_bytes,\n",
    "                          tag=\"v1\")\n",
    "\n",
    "load_model(f\"{DATA_LOCATION}/loan_model.onnx\", rai_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fccbcbd2-beb4-4ba8-9b90-45958aee0139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) \"key\"\n",
      " 2) \"loan_model\"\n",
      " 3) \"type\"\n",
      " 4) \"MODEL\"\n",
      " 5) \"backend\"\n",
      " 6) \"ONNX\"\n",
      " 7) \"device\"\n",
      " 8) \"CPU\"\n",
      " 9) \"tag\"\n",
      "10) \"v1\"\n",
      "11) \"duration\"\n",
      "12) (integer) 0\n",
      "13) \"samples\"\n",
      "14) (integer) 0\n",
      "15) \"calls\"\n",
      "16) (integer) 0\n",
      "17) \"errors\"\n",
      "18) (integer) 0\n"
     ]
    }
   ],
   "source": [
    "# check to make sure the model loaded correctly\n",
    "!redis-cli -h $REDIS_HOST -p $REDIS_PORT AI.INFO loan_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8339d1ec-afdc-4587-93fd-e4303da6909a",
   "metadata": {},
   "source": [
    "## 2.2 Create and Call the Inference DAG\n",
    "\n",
    "After the model is loaded, we contruct a directed acyclic graph (DAG) of commands to run such that each inference call is only one client invocation. This is similar to the `pipeline` feature of normal redis clients.\n",
    "\n",
    "The DAG for the inference workflow is shown below\n",
    "<img src=\"../assets/dag.png\" alt=\"drawing\" style=\"display:block;margin-left:auto;margin-right: auto;width: 60%;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "211ee573-d191-446a-ab78-7626d9b6a242",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_key = 'get_loan_features'\n",
    "model_key = 'loan_model'\n",
    "\n",
    "def get_loan_prediction(dob_ssn: str, zipcode: str, age: int, income: int, emp_length: int, loan_amount: int, int_rate: float):\n",
    "    keys = [dob_ssn, zipcode]\n",
    "    input_args = [str(x) for x in [age, income, emp_length, loan_amount, int_rate]]\n",
    "    out_tag = hash(dob_ssn)\n",
    "\n",
    "    dag = rai_client.dag(persist=[f\"{out_tag}_class\", f\"{out_tag}_prob\"])\n",
    "    dag.scriptexecute(script_key, 'enrich_features', keys=keys, args=input_args, outputs=['model_input'])\n",
    "    dag.modelexecute(model_key, inputs=['model_input'], outputs=[f'{out_tag}_class', f\"{out_tag}_prob\"])\n",
    "    dag.execute()\n",
    "\n",
    "    score = rai_client.tensorget(f'{out_tag}_class')\n",
    "    probabilities = rai_client.tensorget(f\"{out_tag}_prob\")\n",
    "    loan_decision = \"Approved\" if score[0] == 1 else \"Denied\"\n",
    "    return loan_decision, probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e57a71c7-8ba1-4def-a5fc-2fddd91ec0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.42 ms, sys: 0 ns, total: 2.42 ms\n",
      "Wall time: 2.14 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Denied', array([[0.57323503, 0.42676497]], dtype=float32))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_loan_prediction(\"19950809_7983\", \"24265\", 25, 10000, 5, 1000, 6.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71f49ba-43b6-40c4-9ed5-f9ca68ab14fd",
   "metadata": {},
   "source": [
    "# 4.0 Send Inference Requests to the Application\n",
    "\n",
    "The Redis instance is now configured to accept inference requests and run them in addition to housing the stored features. The FastAPI service running alongside this container takes in the same arguments as the function above, and communicates with Redis to run them. \n",
    "\n",
    "This way, we can have a HTTPS based service API with a load balancer in front of our Redis database acting as both the feature store and inference server. In setting up our infrastructure like this, the need to retrieve features from a separate database is eliminated. \n",
    "\n",
    "The following shows how to send a Python based request to that API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad89868d-3788-42c3-9785-2b0aaf124b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision:  Denied \n",
      "Probabilities [0.8414814472198486, 0.15851855278015137] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "SERVER_ADDR = \"172.20.0.30:8877\"\n",
    "\n",
    "request_features = {\n",
    "    \"zipcode\":\"12542\",\n",
    "    \"dob_ssn\":\"19510613_1349\",\n",
    "    \"age\": 29,\n",
    "    \"income\": 100000,\n",
    "    \"emp_length\": 3,\n",
    "    \"loan_amount\": 10000000,\n",
    "    \"int_rate\": 4.2\n",
    "}\n",
    "response = requests.post(f\"http://{SERVER_ADDR}/v1/loan/predict\", data=json.dumps(request_features))\n",
    "data = json.loads(response.text)\n",
    "print(\"\\nDecision: \", data[\"loan_decision\"], \"\\n\"\n",
    "      \"Probabilities\", data[\"probabilities\"], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f128af95-70ea-4f99-bfb3-17ca20398dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision:  Approved \n",
      "Probabilities [0.03905022144317627, 0.9609497785568237] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see what happens when we turn up the interest rate\n",
    "request_features = {\n",
    "    \"zipcode\":\"12542\",\n",
    "    \"dob_ssn\":\"19510613_1349\",\n",
    "    \"age\": 29,\n",
    "    \"income\": 100000,\n",
    "    \"emp_length\": 4,\n",
    "    \"loan_amount\": 10000000,\n",
    "    \"int_rate\": 8.0\n",
    "}\n",
    "response = requests.post(f\"http://{SERVER_ADDR}/v1/loan/predict\", data=json.dumps(request_features))\n",
    "data = json.loads(response.text)\n",
    "print(\"\\nDecision: \", data[\"loan_decision\"], \"\\n\"\n",
    "      \"Probabilities\", data[\"probabilities\"], \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
